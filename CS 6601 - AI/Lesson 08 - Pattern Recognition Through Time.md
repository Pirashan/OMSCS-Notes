# Lesson 8

In this lesson we will examine how pattern recognition works with time series data. We will also examine [dynamic time wrap](https://en.wikipedia.org/wiki/Dynamic_time_warping) and [hidden Markov models](https://en.wikipedia.org/wiki/Hidden_Markov_model).

## Dynamic Time Warping

Euclidean distance is one of the more commonly used metrics used to gauge similarity. However, this metric is sensitive to distortions along the time axes. **DTW (dynamic time warping)** is one of the algorithms in time series analysis that measures similarity between two temporal sequences which may vary in speed. This can help with problems such as speech recognition.

DTW calculates an optimal match between two given sequences with specific restrictions and rules. From Wiki:

> - Every index from the first sequence must be matched with one or more indices from the other sequence, and vice versa
> - The first index from the first sequence must be matched with the first index from the other sequence (but it does not have to be its only match)
> - The last index from the first sequence must be matched with the last index from the other sequence (but it does not have to be its only match)
> - The mapping of the indices from the first sequence to indices from the other sequence must be monotonically increasing, and vice versa, i.e. if $j > i$ are indices from the first sequence, then there must not be two indices $l > k$ in the other sequence, such that index $i$ is matched with index $l$ and index $j$ is matched with index $k$, and vice versa
>
> The optimal match is denoted by the match that satisfies all the restrictions and the rules and that has the minimal cost, where the cost is computed as the sum of absolute differences, for each matched pair of indices, between their values.

What happens when two signals are not similar? In this case, DTW could allow them to match a lot better than they should. We can bound (via [Sakoe-Chiba Band](https://perun.pmf.uns.ac.rs/radovanovic/publications/2019-inista-dtw.pdf)) how much warping can deviate from the diagonal (the case when signals are exactly the same) to only include reasonable warping in our solution.

However, note that DTW can get complicated if sections of the time series require different bounds due to variability.

## Hidden Markov Model

An alternative to DTW is **HMM (hidden Markov model)** which assumes that the system being modeled is a [Markov process](https://en.wikipedia.org/wiki/Markov_chain) there is another process $Y$ whose behavior depends on $X$. The goal of HMM is to learn about $X$ by observing $Y$.

Components of HMM include:

- $X_0$: the initial state
- $X_k$ and $E_k$: the state and output at time $k$
- $X_t$ and $E_t$: the final state and output at time $t$

For HMM diagrams, one trick to calculate number of expected time frames we expect to stay at a given state is through $n_{expected} = \frac{1}{1 - p_{self}}$ where $p_{self}$ is the self-transition probability. To determine the self-transition probability, we can use $p_{self} = 1 - p_{transition}$ where $p_{transition} = \frac{1}{n}$ and $n$ is the number of time frames before a transition.

## Viterbi Trellis

How do we go about forming recognition with HMM? We can use **Viterbi Trellis (Viterbi algorithm)** to obtain the [MAP (maximum posterior probability)](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation) estimate of the most likely sequence of hidden states (a.k.a. _Viterbi path_) that results in a sequence of observed events.

Consequently, the goal of the Viterbi algorithm is to find $P(O | \lambda)$ where $O$ is the set of observations (query values) generated by the HMM and $\lambda$ is the model of the state (evidence).

Once we have all values filled out in the Viterbi diagram, we determine the most likely path by taking the path that yields the greater product of transition probability $p_{transition}$ and output probability $p_{output}$. Then the path probability can be determined by taking the product of all products along the Viterbi path:

$P(O | \lambda) = \prod p_{transition} * p_{output}$

## HMM Training

In practice we train HMM directly with data. The training steps are as follows:

1. Split the data into equal parts (transitions) for each example
2. Calculate the transition probability $p_{transition}$ (typically done wth estimation $p_{transition} = \frac{n_{transitions}}{n_time_frames}$) and the self-transition probability $p_{self}$
3. Determine the Gaussian distribution along with the mean and standard deviation for each set of transition data (typical $\Delta$ observations) in each example
4. Iterate and adjust the transition probabilities and time frame boundaries until a solution is converged (similar to EM)

Another popular method to train HMMs is using the [Baum-Welch algorithm](https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm) (a special case of EM) which uses the [forward-backward algorithm](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm) to compute statistics of the expectation step and keep track of calculations. Baum-Welch asserts that every sample of the data contributes to every state proportionately to the probability of that frame of data being in that state.

Other HMM training tips include:

- To incorporate more features (dimensions) for each state (per time frame) in our HMM, we can simply add those dimensions to the output probabilities
- We can use a mixture of Gaussians to model non-Gaussian output probabilities

When training HMMs to recognize speech, additional tips include:

- Using [stochastic beam search](https://en.wikipedia.org/wiki/Beam_search) (same as beam search but chooses the next $n$ states randomly) to prune paths randomly in proportion to their probability
- Using _context training_ whereby the each word is concatenated in a phrase and trained on instead on one word at a time. After convergence we can go back and train based on smaller parts of phrases (using a method like Baum-Welch). The result of context training can divide our error rate in _half_
- Using _statistical grammar_ whereby recognition is biased towards distribution of occurrence of phrases or words following a phrase or word which can divide our error rate by _four_
- Combining context training with statistical grammar to further reduce the error rate
- Combining states in phrases which have similar mean and variance during training (note that this should be done conservatively since the feature statistics can look very different)

We might also try a recent novel method to boost HMM performance via **segmentally boosted HMMs** which combines the benefits of discriminate models with generative models as follows:

1. Align and train the HMMs as normal
2. Use the training to align the data that belongs to each state
3. Examine each state in each model iteratively
4. Boost by selecting features which optimally differentiate the data for chosen state versus the rest of the states
5. Weigh the features (dimensions) appropriately in the HMM

In general, normal HMMs (unmodified HMMs) should not be used to generate data because the output distributions do not incorporate continuity. We want to model state transitions with HMMs but use a different process where each state is more aware of the context to generate the data (e.g., [HMMs combined with deep belief networks](https://journal.hep.com.cn/ckcest/fitee/EN/article/downloadArticleFile.do?attachType=PDF&id=20775)).

## Section Quizzes

**Note**: will be somewhat limited for this semester.

### Delta-y Quiz

_Given the plots and derivatives (provided), match the correct plots with their derivatives_.

1. A
2. C
3. B
4. D

### _I_ Versus _We_ Quiz

_What property of the observed sequence of $\Delta y$ can help distinguish between the two gestures_?

- Probability distributions in middle states
- Likely time spent in middle states

### _I_ Transitions Quiz

_Given the HMM (provided), what state are we in at $t = 6$ and $t = 7$_?

- When $t = 6$ we are in states $S_2$ and $S_3$
- When $t = 7$ we are in state $S_3$

### Nodes For _I_

_Given the HMM (provided), what are the output probabilities for $t = 5$_.

- $P(S_1) = 10^-4$
- $P(S_2) = 10^-6$
- $P(S_3) = 0.8$

### _We_ Transitions Quiz

_Given the HMM (provided), fill in the probabilities._

1. 0.8
2. 0.2
3. 0.8
4. 0.2
5. 0.7
6. 0.3
7. 0.8
8. 0.2
9. 0.7
10. 0.3
11. 0.8
12. 0.8
13. 0.2
14. 0.7
15. 0.3
16. 0.8
17. 0.2
18. 0.7
19. 0.3
20. 0.8
21. 0.3
22. 0.8

### _We_ Output Probabilities Quiz

_Given the HMM (provided), what are the output probabilities for $t = 5$_.

1. E
2. D
3. B
4. D
5. B
6. C

### New Observation Sequence For _I_

_Let's examine how longer observations can affect our final output probabilities. Replace the middle $O$ observation (from the given HMM) with the sequence `-1`, `0`, and `1`, then compute $P(O | \lambda_I)$_.

We are provided with:

$O = 3, 7, 4, -1, 0, 1, -5, -5, -3\\$

$P(-1 | S_1) = 0.005\\$
$P(-1 | S_2) = 0.4\\$
$P(-1 | S_3) = 0.015\\$
$P(1 | S_1) = 0.015\\$
$P(1 | S_2) = 0.04\\$
$P(1 | S_3) = 0.005\\$

Therefore, $P(O | \lambda_I) = 1.42 * 10^-5$.

### New Observation Sequence For _WE_

_Let's examine how longer observations can affect our final output probabilities. Replace the middle $O$ observation (from the given HMM) with the sequence `-1`, `0`, and `1`, then compute $P(O | \lambda_{We})$\_.

We are provided with:

$O = 3, 7, 4, -1, 0, 1, -5, -5, -3\\$

$P(-1 | S_1) = 0.005\\$
$P(-1 | S_2) = 0.6\\$
$P(-1 | S_3) = 0.015\\$
$P(1 | S_1) = 0.015\\$
$P(1 | S_2) = 0.6\\$
$P(1 | S_3) = 0.005\\$

Therefore, $P(O | \lambda_{We}) = 2.91 * 10^-5$.
